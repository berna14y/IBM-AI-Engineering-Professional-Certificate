{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b80864-134b-4e19-b978-042c3752181d",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \">\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5bdfa8-6014-495e-af4c-1905a13cf122",
   "metadata": {},
   "source": [
    "<h1><h1>Pre-trained-Models with PyTorch </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53741054-55b8-4d99-9976-6032dbb90087",
   "metadata": {},
   "source": [
    "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n",
    "<ul>\n",
    "<li>change the output layer</li>\n",
    "<li> train the model</li> \n",
    "<li>  identify  several  misclassified samples</li> \n",
    " </ul>\n",
    "You will take several screenshots of your work and share your notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c08cf-34b0-406d-8125-0593277f34bc",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f07a2-6a2d-4608-84f2-0cc62bf2501b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
    "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
    "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
    "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
    "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
    "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
    " </div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb7083-02ed-4c9c-b5b4-7b0418388a2a",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efedf9be-c643-4d62-8158-0918061c6b8b",
   "metadata": {},
   "source": [
    "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5119dc8-afc5-460d-879a-8b774f567bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
    "#!unzip -q Negative_tensors.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip -q Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad15709-e387-40fd-ab2f-8fde44dea3e1",
   "metadata": {},
   "source": [
    "We will install torchvision:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720b2e1a-fa06-4daf-a922-4a70777f6709",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadbf87-12b4-4cf5-973b-d074375b21f7",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100c4913-0f97-425c-bf42-eba819ed5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f99d05a95f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pandas\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62927ada-7de8-485c-a08e-cb2b038b25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed9c29-48b2-4bbf-9ba9-7f6fc1c088a2",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b81ceb-2ff9-4e71-b0ad-bcd507f91029",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630dc80-3ee1-40a4-84d7-0427cd7101c7",
   "metadata": {},
   "source": [
    " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2612bc-5ed4-4f7d-bc9d-71c6a69ce2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create your own dataset object\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"/Users/bernayilmaz/Desktop\"\n",
    "        positive=\"Positive_tensors\"\n",
    "        negative='Negative_tensors'\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:30000]\n",
    "            self.Y=self.Y[0:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)     \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "               \n",
    "        image=torch.load(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "                  \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747173bb-89d3-45e8-b058-ab209f14610c",
   "metadata": {},
   "source": [
    "We create two dataset objects, one for the training data and one for the validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0618234d-d2a4-459a-aed0-20e3803a4661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train=True)\n",
    "validation_dataset = Dataset(train=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d6186-c5e3-4594-b469-fc776d407fe5",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_1\">Question 1</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3bc6f-c9ce-4bc6-98e2-160b4c2c6be3",
   "metadata": {},
   "source": [
    "<b>Prepare a pre-trained resnet18 model :</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd3ebc-0de2-4418-9316-a20a12ec7034",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "293cde0f-d36f-4584-a1ff-d4fe736b9fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernayilmaz/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/bernayilmaz/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/bernayilmaz/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████████████████████████████████| 44.7M/44.7M [00:09<00:00, 4.72MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the pre-trained model resnet18\n",
    "\n",
    "# Type your code here\n",
    "model = models.resnet18(pretrained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b310a4-2eb5-4627-ae5e-d0783ba838ad",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ed14f3-ded5-47a6-b667-34e9d5bc0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "\n",
    "\n",
    "# Type your code here\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f23176-eca4-4e8f-9ec2-a164a5a7ef65",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410287ff-6594-4af8-8acc-495106d31545",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f79a8c7-4e3c-48b2-8d5c-75ec66fc7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fe114-92ee-4c41-aede-1e016711ffcd",
   "metadata": {},
   "source": [
    "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1462f12b-da03-4175-ad74-043e46166410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb183bcf-8cfa-4e48-93e8-af78f42e57b0",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91768582-592a-4360-b47c-1c7db7008ff8",
   "metadata": {},
   "source": [
    "In this question you will train your, model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455f1a9-a0af-4502-9179-0a4693cf06d8",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5263c76f-483d-42bf-9716-c526278d3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "\n",
    "# Type your code here\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f9645-a2ff-4900-91e7-4acf3eec2427",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f006c789-b1d6-4eb9-bdc4-613265ac440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 100)\n",
    "validation_loader = DataLoader(dataset = validation_dataset, batch_size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a965344-294c-4f35-881b-6f3b7e938149",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ffbf141-4354-429f-ba64-cf0fecf4d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f8e4c-8cc9-477a-b291-3aedf0d0852e",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f9e3b-f4a4-430d-92e4-2b204f4f9162",
   "metadata": {},
   "source": [
    "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10db4f0-56f4-4c94-940f-133f5764ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=1\n",
    "loss_list=[]\n",
    "accuracy_list=[]\n",
    "correct=0\n",
    "N_test=len(validation_dataset)\n",
    "N_train=len(train_dataset)\n",
    "#n_epochs\n",
    "\n",
    "Loss=0\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    loss_sublist = []\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        model.train() \n",
    "        #clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        yhat = model(x)\n",
    "        # calculate loss \n",
    "        loss = criterion(yhat,y)\n",
    "        loss_sublist.append(loss.data.item())\n",
    "        # calculate gradients of parameters\n",
    "        loss.backward()\n",
    "        # update parameters \n",
    "        optimizer.step()\n",
    "        loss_list.append(np.mean(loss_sublist))\n",
    "            \n",
    "            \n",
    "    correct=0\n",
    "  \n",
    "    for x_test, y_test in validation_loader:\n",
    "        # set model to eval \n",
    "        model.eval()\n",
    "        #make a prediction \n",
    "        yhat = model(x_test)        \n",
    "        #find max \n",
    "        _ , yhat = torch.max(yhat.data,1)\n",
    "        #Calculate misclassified  samples in mini-batch \n",
    "        #hint +=(yhat==y_test).sum().item()\n",
    "        correct += (yhat == y_test).sum().item()        \n",
    " \n",
    "   \n",
    "    accuracy=correct/N_test\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f3003-c65d-40bc-96ad-5c9c48c99f3b",
   "metadata": {},
   "source": [
    "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f321eee5-544b-4659-839f-0e6ea591d09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9935"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c7ae1d7-abbd-4e21-b0f2-9e45b967a1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDz0lEQVR4nO3deXxU9b3/8fdkkpnJOiF7ICGEfZUlKAYFcUvFpVKrova6tFrLvS4Xsbctl3pVbttYWxX9IbRWLdq60Lq1t6I2VmQRF4hBEFC2QAIkhCRkT2aSzPn9MWQ0BkIISc7M5PV8PM4jmTNnZj5zPJL34/v9nu/XYhiGIQAAgCARYnYBAAAAPYlwAwAAggrhBgAABBXCDQAACCqEGwAAEFQINwAAIKgQbgAAQFAJNbuAvubxeHTo0CFFR0fLYrGYXQ4AAOgCwzBUW1urgQMHKiSk87aZfhduDh06pPT0dLPLAAAA3VBcXKy0tLROj+l34SY6OlqS9+TExMSYXA0AAOiKmpoapaen+/6Od6bfhZu2rqiYmBjCDQAAAaYrQ0oYUAwAAIIK4QYAAAQVwg0AAAgqhBsAABBUCDcAACCoEG4AAEBQMT3cLFu2TJmZmXI4HMrKytK6detOeOwtt9wii8XSYRs3blwfVgwAAPyZqeFm5cqVmj9/vhYtWqSCggLNmDFDs2fPVlFR0XGPf/zxx1VSUuLbiouLFRcXp2uuuaaPKwcAAP7KYhiGYdaHT5s2TVOmTNHy5ct9+8aMGaM5c+YoNzf3pK9/4403dNVVV6mwsFAZGRnHPcblcsnlcvket81wWF1dzSR+AAAEiJqaGjmdzi79/Tat5cbtdis/P185OTnt9ufk5GjDhg1deo9nnnlGF1100QmDjSTl5ubK6XT6NtaVAgAguJkWbsrLy9Xa2qrk5OR2+5OTk1VaWnrS15eUlOitt97Sbbfd1ulxCxcuVHV1tW8rLi4+rboBAIB/M31tqW+uEWEYRpfWjVixYoViY2M1Z86cTo+z2+2y2+2nUyIAAAggprXcJCQkyGq1dmilKSsr69Ca802GYejZZ5/VjTfeKJvN1ptlnpLqxmZtLq4yuwwAAPo108KNzWZTVlaW8vLy2u3Py8vT9OnTO33tmjVrtHv3bt166629WeIpKSg6qmm/elfz/pSvllaP2eUAANBvmXor+IIFC/T000/r2Wef1Y4dO3TPPfeoqKhI8+bNk+QdL3PTTTd1eN0zzzyjadOmafz48X1d8gmNHRij8DCrSmuatGbnEbPLAQCg3zJ1zM3cuXNVUVGhxYsXq6SkROPHj9eqVat8dz+VlJR0mPOmurpar776qh5//HEzSj4he6hV352SpqfXF+qlT4p14ZjOu9YAAEDvMHWeGzOcyn3yp2p3Wa0uenStrCEWbfjZBUqOcfTo+wMA0F8FxDw3wWh4UrTOHDJArR5Df998yOxyAADolwg3PeyiY91RBcVHTa4EAID+iXDTwyYMckqSthyoNrkSAAD6J8JNDxt3LNwcONqoo/Vuk6sBAKD/Idz0MGd4mIbER0iSth6k9QYAgL5GuOkF44+13hBuAADoe4SbXnBG2rFww7gbAAD6HOGmF9ByAwCAeQg3vWDcQG+4OVjVqNqmZpOrAQCgfyHc9AJneJgSoryrle8rbzC5GgAA+hfCTS8ZEh8pSSqsqDe5EgAA+hfCTS/JTPCGm33lhBsAAPoS4aaXDDkWbgoJNwAA9CnCTS/JJNwAAGAKwk0v8XVLMeYGAIA+RbjpJW0DiqsamlXVwBpTAAD0FcJNLwm3WZUS45BE1xQAAH2JcNOLGHcDAEDfI9z0oiG+cTdM5AcAQF8h3PSitAHhkqRDVY0mVwIAQP9BuOlFg2IJNwAA9DXCTS8aSLgBAKDPEW560cBY791Sh6qb5PEYJlcDAED/QLjpRckxDlkskrvFo4p65roBAKAvEG56UZg1RMnRx1pv6JoCAKBPEG56ma9rinADAECfINz0Mt+g4uomkysBAKB/INz0Mm4HBwCgbxFuehm3gwMA0LcIN72McAMAQN8i3PSytgHFB6sYcwMAQF8g3PSytjE35XUuNbpbTa4GAIDgR7jpZc7wMDnDwyRJ+yrqTa4GAIDgR7jpZRaLRUMTIyVJheWEGwAAehvhpg8MTYiSJO09UmdyJQAABD/CTR9oa7nZS8sNAAC9jnDTB4YmHAs3Rwg3AAD0NsJNH8hsa7k5UifDMEyuBgCA4Ea46QND4iNlsUg1TS2qrHebXQ4AAEGNcNMHHGFWDXR657vhjikAAHoX4aaP+AYVM+4GAIBeRbjpI22DiveUczs4AAC9iXDTR4YnR0uSdh8m3AAA0JsIN31kRJJ3Ir9dZYQbAAB6k+nhZtmyZcrMzJTD4VBWVpbWrVvX6fEul0uLFi1SRkaG7Ha7hg0bpmeffbaPqu2+tnBTfLSBBTQBAOhFoWZ++MqVKzV//nwtW7ZM55xzjn7/+99r9uzZ2r59uwYPHnzc11x77bU6fPiwnnnmGQ0fPlxlZWVqaWnp48pPXXyUXXGRNlXWu7XnSJ3GD3KaXRIAAEHJYpg4q9y0adM0ZcoULV++3LdvzJgxmjNnjnJzczsc//bbb+u6667T3r17FRcX163PrKmpkdPpVHV1tWJiYrpde3dc+/sP9UlhpZbMnaQ5kwf16WcDABDITuXvt2ndUm63W/n5+crJyWm3PycnRxs2bDjua/7+979r6tSpevjhhzVo0CCNHDlSP/7xj9XY2HjCz3G5XKqpqWm3meWrcTe1ptUAAECwM61bqry8XK2trUpOTm63Pzk5WaWlpcd9zd69e7V+/Xo5HA69/vrrKi8v13/8x3+osrLyhONucnNz9eCDD/Z4/d3hCzfcMQUAQK8xfUCxxWJp99gwjA772ng8HlksFr3wwgs666yzdOmll+rRRx/VihUrTth6s3DhQlVXV/u24uLiHv8OXTWi7XZw7pgCAKDXmNZyk5CQIKvV2qGVpqysrENrTpvU1FQNGjRITudXg3HHjBkjwzB04MABjRgxosNr7Ha77HZ7zxbfTW0tN/sq6tXU3CpHmNXkigAACD6mtdzYbDZlZWUpLy+v3f68vDxNnz79uK8555xzdOjQIdXVfdXysXPnToWEhCgtLa1X6+0JidF2JUTZ5DGk7SXmjf0BACCYmdottWDBAj399NN69tlntWPHDt1zzz0qKirSvHnzJHm7lG666Sbf8TfccIPi4+P1/e9/X9u3b9fatWv1X//1X/rBD36g8PBws75Gl1ksFp2RFitJ2lJcZWotAAAEK1PnuZk7d64qKiq0ePFilZSUaPz48Vq1apUyMjIkSSUlJSoqKvIdHxUVpby8PN11112aOnWq4uPjde211+oXv/iFWV/hlJ2R5tR7X5Rpy4Fqs0sBACAomTrPjRnMnOdGklZ/Uabvr9iooYmReu/eWX3++QAABKKAmOemvzojzTsYeu+RetU0NZtcDQAAwYdw08fio+waFOsdH/Q5XVMAAPQ4wo0JJqZ7W28+I9wAANDjCDcmGJvq7StkGQYAAHoe4cYEmQneyfwKy+tNrgQAgOBDuDHBkIQISdI+wg0AAD2OcGOCIfGRkqSjDc2qanCbXA0AAMGFcGOCSHuokmO8613RNQUAQM8i3JgkM8HberOvgnADAEBPItyYpC3cFJY3mFwJAADBhXBjkrZxN3RLAQDQswg3JvF1SxFuAADoUYQbk3zVLVWvfrZ2KQAAvYpwY5LB8RGyhlhU52rR4RqX2eUAABA0CDcmsYdafa03O0prTK4GAIDgQbgx0Zhja0x9UcIaUwAA9BTCjYlGp0RLknaU0HIDAEBPIdyYqG118C/olgIAoMcQbkw0OtXbcrPnSL2amltNrgYAgOBAuDFRSoxDsRFhavUY2l1WZ3Y5AAAEBcKNiSwWi2/czRelDCoGAKAnEG5M1nbHFIOKAQDoGYQbk41JYVAxAAA9iXBjsq9abmpZhgEAgB5AuDHZiOQohVikynq3jtSyDAMAAKeLcGMyR5hVQxOjJEnbGXcDAMBpI9z4Ae6YAgCg5xBu/AB3TAEA0HMIN35gzLGZillAEwCA00e48QNtLTd7jtSxDAMAAKeJcOMHUmIciou0qcVjMO4GAIDTRLjxAxaLRRMGOSVJWw5UmVsMAAABjnDjJyamecPNZ8XVJlcCAEBgI9z4iTPSYiXRcgMAwOki3PiJM9K9LTe7j9SpztVicjUAAAQuwo2fSIp2KNXpkGFInx+kawoAgO4i3PiRM46Nu9l6gHADAEB3EW78SNu4m88YdwMAQLcRbvzIRN+gYlpuAADoLsKNH5lwrFuqqLJBR+vdJlcDAEBgItz4EWd4mDITIiVJWxhUDABAtxBu/EzboOItxVXmFgIAQIAi3PiZrwYV03IDAEB3EG78TNsyDMxUDABA95gebpYtW6bMzEw5HA5lZWVp3bp1Jzz2/fffl8Vi6bB98cUXfVhx7xo30ClriEVltS6VVjeZXQ4AAAHH1HCzcuVKzZ8/X4sWLVJBQYFmzJih2bNnq6ioqNPXffnllyopKfFtI0aM6KOKe1+4zaoRSVGSmO8GAIDuMDXcPProo7r11lt12223acyYMVqyZInS09O1fPnyTl+XlJSklJQU32a1Wvuo4r4xkUU0AQDoNtPCjdvtVn5+vnJyctrtz8nJ0YYNGzp97eTJk5WamqoLL7xQq1ev7vRYl8ulmpqadpu/a1tEk8n8AAA4daaFm/LycrW2tio5Obnd/uTkZJWWlh73NampqXrqqaf06quv6rXXXtOoUaN04YUXau3atSf8nNzcXDmdTt+Wnp7eo9+jN3x9pmLDMMwtBgCAABNqdgEWi6XdY8MwOuxrM2rUKI0aNcr3ODs7W8XFxfrtb3+rmTNnHvc1Cxcu1IIFC3yPa2pq/D7gjEqJli00RNWNzdpf0aAhxyb2AwAAJ2day01CQoKsVmuHVpqysrIOrTmdOfvss7Vr164TPm+32xUTE9Nu83dh1hCNTfXWyaBiAABOjWnhxmazKSsrS3l5ee325+Xlafr06V1+n4KCAqWmpvZ0eaZrm+9mMzMVAwBwSkztllqwYIFuvPFGTZ06VdnZ2XrqqadUVFSkefPmSfJ2KR08eFDPP/+8JGnJkiUaMmSIxo0bJ7fbrT//+c969dVX9eqrr5r5NXrF1CFxeu7D/fpob6XZpQAAEFBMDTdz585VRUWFFi9erJKSEo0fP16rVq1SRkaGJKmkpKTdnDdut1s//vGPdfDgQYWHh2vcuHF68803demll5r1FXpN9rB4SdKOkhpV1LkUH2U3uSIAAAKDxehnt+PU1NTI6XSqurra78ffXLJkrb4ordXSGybr8jMGml0OAACmOZW/36Yvv4ATmz4sQZK0YU+FyZUAABA4CDd+bPqxrqkNu8tNrgQAgMBBuPFj04bGyRpi0b6KBpVUN5pdDgAAAYFw48eiHWEalRwtSSooqjK3GAAAAgThxs9NyYiVJH26/6i5hQAAECAIN35ucvoASVIBk/kBANAlhBs/NyXDG262HqyWu8VjcjUAAPg/wo2fGxIfodiIMLlbPNpRUmN2OQAA+D3CjZ+zWCyanB4rSfq0iHE3AACcDOEmAEwZfGzcDXdMAQBwUoSbADC5LdwU03IDAMDJEG4CwMR0pywWqbiyUUdqXWaXAwCAXyPcBIBoR5hGJrVN5kfrDQAAnSHcBIjJg2MlMd8NAAAnQ7gJEG2DipmpGACAzhFuAkRby82WA9VqaWUyPwAAToRwEyCGJUYpxhGqxuZWfX6IyfwAADgRwk2ACAmxKHtYvCTpg93lJlcDAID/ItwEkHOHJ0gi3AAA0BnCTQCZfizcbNp3VI3uVpOrAQDAPxFuAsjQhEilOh1yt3q0aX+l2eUAAOCXCDcBxGKx6Bxf11SFydUAAOCfCDcBhnE3AAB0jnATYKYP994x9fmhah2td5tcDQAA/odwE2CSoh0amRwlw5A+3EvXFAAA30S4CUBt427W0zUFAEAHhJsA1DbuZgPhBgCADgg3AWja0HiFhli0r6JBxZUNZpcDAIBfIdwEoCh7qG+V8DU7j5hcDQAA/oVwE6DOG5UoSXr/S8INAABfR7gJUOeN9IabDXvK5WphKQYAANoQbgLU2NQYJUTZ1eBuVf6+o2aXAwCA3yDcBKiQEItmjvTeNbX6yzKTqwEAwH8QbgLYhaOTJUlvbyuVYRgmVwMAgH8g3ASw80cnKjzMquLKRm09WG12OQAA+AXCTQCLsIXqgjFJkqQ3t5SYXA0AAP6BcBPgLp+QKkn6x5YSuqYAABDhJuDNGpWkCJtVB6sa9dkBuqYAACDcBLhwm1UXjvEOLH5zyyGTqwEAwHyEmyBw2bGuqTfpmgIAgHATDGaNSlSkzapD1U0qKK4yuxwAAExFuAkCjjCrLh7b1jXFXVMAgP6NcBMkLjtjoCRp1dYSeTx0TQEA+i/CTZCYMSJB0fZQlVQ36dMi1poCAPRfpoebZcuWKTMzUw6HQ1lZWVq3bl2XXvfBBx8oNDRUkyZN6t0CA8TXu6b+QdcUAKAfMzXcrFy5UvPnz9eiRYtUUFCgGTNmaPbs2SoqKur0ddXV1brpppt04YUX9lGlgeGyM7x3TdE1BQDoz7oVbp577jm9+eabvsc/+clPFBsbq+nTp2v//v1dfp9HH31Ut956q2677TaNGTNGS5YsUXp6upYvX97p6370ox/phhtuUHZ2dnfKD1rnjkhQtCNUZbUu7poCAPRb3Qo3v/rVrxQeHi5J+vDDD7V06VI9/PDDSkhI0D333NOl93C73crPz1dOTk67/Tk5OdqwYcMJX/fHP/5Re/bs0f3339+lz3G5XKqpqWm3BSt7qFUzRyZKktZ8WWZyNQAAmKNb4aa4uFjDhw+XJL3xxhu6+uqrdfvttys3N7fLY2bKy8vV2tqq5OTkdvuTk5NVWlp63Nfs2rVLP/vZz/TCCy8oNDS0S5+Tm5srp9Pp29LT07v0ukB1/ijvQpqrvzxiciUAAJijW+EmKipKFRUVkqR//vOfuuiiiyRJDodDjY2Np/ReFoul3WPDMDrsk6TW1lbdcMMNevDBBzVy5Mguv//ChQtVXV3t24qLi0+pvkBz3rGWm60Hq1VW22RyNQAA9L2uNX98w8UXX6zbbrtNkydP1s6dO3XZZZdJkrZt26YhQ4Z06T0SEhJktVo7tNKUlZV1aM2RpNraWm3atEkFBQW68847JUkej0eGYSg0NFT//Oc/dcEFF3R4nd1ul91uP8VvGLgSo+2aMMiprQertXZnua7OSjO7JAAA+lS3Wm6efPJJZWdn68iRI3r11VcVHx8vScrPz9f111/fpfew2WzKyspSXl5eu/15eXmaPn16h+NjYmK0detWbd682bfNmzdPo0aN0ubNmzVt2rTufJWgdP4ob+vNv3YcNrkSAAD6XrdabmJjY7V06dIO+x988MFTep8FCxboxhtv1NSpU5Wdna2nnnpKRUVFmjdvniRvl9LBgwf1/PPPKyQkROPHj2/3+qSkJDkcjg77+7uccSl64r3deu+LMtU2NSvaEWZ2SQAA9Jlutdy8/fbbWr9+ve/xk08+qUmTJumGG27Q0aNdnx137ty5WrJkiRYvXqxJkyZp7dq1WrVqlTIyMiRJJSUlJ53zBh2NGxijoYmRcrV49C6tNwCAfsZiGMYpz/Y2YcIE/frXv9all16qrVu36swzz9SCBQv03nvvacyYMfrjH//YG7X2iJqaGjmdTlVXVysmJsbscnrNY3k79fi/dun8UYn64/fPMrscAABOy6n8/e5Wy01hYaHGjh0rSXr11Vd1+eWX61e/+pWWLVumt956qztviR727UnehTTX7SpXZb3b5GoAAOg73Qo3NptNDQ0NkqR3333XNxFfXFxcUE+SF0iGJUZpwiCnWjyGXvv0gNnlAADQZ7oVbs4991wtWLBA//u//6tPPvnEdyv4zp07lZbGrcf+4rqzvBMWvvRJkbrR+wgAQEDqVrhZunSpQkND9corr2j58uUaNGiQJOmtt97SJZdc0qMFovu+PXGgwsOs2nOkXpv2d32gNwAAgaxbA4oDWX8ZUNzmp69s0cpNxbpqyiA9eu0ks8sBAKBbTuXvd7fmuZG8yyG88cYb2rFjhywWi8aMGaMrr7xSVqu1u2+JXnD11DSt3FSsvG2H1dTcKkcY/30AAMGtW+Fm9+7duvTSS3Xw4EGNGjVKhmFo586dSk9P15tvvqlhw4b1dJ3opqzBA5QS41BpTZPW7SrXxWM7Lm0BAEAw6daYm7vvvlvDhg1TcXGxPv30UxUUFKioqEiZmZm6++67e7pGnIaQEIsunZAqSXpzyyGTqwEAoPd1K9ysWbNGDz/8sOLi4nz74uPj9dBDD2nNmjU9Vhx6xmVneMNN3nZv1xQAAMGsW+HGbrertra2w/66ujrZbLbTLgo9a3J6rAbFhqve3aq87SzHAAAIbt0KN5dffrluv/12ffzxxzIMQ4Zh6KOPPtK8efP07W9/u6drxGkKCbHou1ne+YdWbiw2uRoAAHpXt8LNE088oWHDhik7O1sOh0MOh0PTp0/X8OHDtWTJkh4uET3hmqw0WSzS+t3lKq5sMLscAAB6TbfuloqNjdXf/vY37d69Wzt27JBhGBo7dqyGDx/e0/Whh6THRejc4Qlat6tcf9lUrHtzRpldEgAAvaLL4WbBggWdPv/+++/7fn/00Ue7XRB6z3VnDta6XeX666YD+s8LRyjU2q2GOwAA/FqXw01BQUGXjrNYLN0uBr3rorFJiou0qbSmSWt3HdEFo5nzBgAQfLocblavXt2bdaAP2EOtumryID29vlAvf1JMuAEABCX6JfqZtpXC//VFmcpqmkyuBgCAnke46WeGJ0VrasYAtXoMvfLpAbPLAQCgxxFu+qG5Z3pbb1ZuLFY/WxQeANAPEG76ocvOSFWUPVT7Kxr00d5Ks8sBAKBHEW76oQhbqL49aaAk6cVPikyuBgCAnkW46aduOGuwJGnV1hIdqmo0uRoAAHoO4aafGj/Iqeyh8Wr1GFqxYZ/Z5QAA0GMIN/3Y7TOHSpJe+rhItU3NJlcDAEDPINz0Y+eNTNTwpCjVulpYLRwAEDQIN/1YSIhFP5yRKUl6dn2hmls9JlcEAMDpI9z0c1dOGqSEKJsOVTdp1dYSs8sBAOC0EW76OUeYVTdnD5Ek/WHdXib1AwAEPMIN9G9nZ8gRFqLPD9YwqR8AIOARbqABkTZdnZUmydt6AwBAICPcQJJ067lDZbFI731Rpi9Ka8wuBwCAbiPcQJKUmRCpS8enSpJ+8/aXJlcDAED3EW7gsyBnpKwhFv3rizJ9vLfC7HIAAOgWwg18hiVG6boz0yVJuW99wZ1TAICARLhBO/950QhF2KzaXFyltz8vNbscAABOGeEG7SRFO3TbDO+aUw+/8yWzFgMAAg7hBh3cPnOo4iNtKiyv18usOQUACDCEG3QQZQ/V3ReOkCQ9/u4u1btaTK4IAICuI9zguK4/a7Ay4iNUXufS0+sKzS4HAIAuI9zguGyhIfpxzihJ0lNr96i8zmVyRQAAdA3hBid02YRUnZHmVL27VU/8a5fZ5QAA0CWEG5xQSIhFP5s9WpL04sdF2nukzuSKAAA4OcINOjV9WILOH5WoFo+hB/9vOxP7AQD8HuEGJ3Xf5WMVZrVozc4j+uf2w2aXAwBAp0wPN8uWLVNmZqYcDoeysrK0bt26Ex67fv16nXPOOYqPj1d4eLhGjx6txx57rA+r7Z+GJkbp9pneif1+tWqHWpjYDwDgx0wNNytXrtT8+fO1aNEiFRQUaMaMGZo9e7aKioqOe3xkZKTuvPNOrV27Vjt27NDPf/5z/fznP9dTTz3Vx5X3P/8xa7jiI23aX9Gg1z49aHY5AACckMUwcRDFtGnTNGXKFC1fvty3b8yYMZozZ45yc3O79B5XXXWVIiMj9ac//alLx9fU1MjpdKq6uloxMTHdqru/+sPavfrlqh1KGxCu9+6dJVuo6Q1/AIB+4lT+fpv218ntdis/P185OTnt9ufk5GjDhg1deo+CggJt2LBB55133gmPcblcqqmpabehe/7t7AwlRtt14GijVmxgYj8AgH8yLdyUl5ertbVVycnJ7fYnJyertLTz1ajT0tJkt9s1depU3XHHHbrttttOeGxubq6cTqdvS09P75H6+6Nwm1X/dWxiv8fydulgVaPJFQEA0JHp/QoWi6XdY8MwOuz7pnXr1mnTpk363e9+pyVLluill1464bELFy5UdXW1bysuZiHI03HN1DSdNSROjc2tuu+Nz7k1HADgd0LN+uCEhARZrdYOrTRlZWUdWnO+KTMzU5I0YcIEHT58WA888ICuv/764x5rt9tlt9t7pmjIYrHol98Zr8ueWK/3vijTyo3Fuu6swWaXBQCAj2ktNzabTVlZWcrLy2u3Py8vT9OnT+/y+xiGIZeLdY/60ojkaP34WyMlSf/7j+0qqmgwuSIAAL5iWsuNJC1YsEA33nijpk6dquzsbD311FMqKirSvHnzJHm7lA4ePKjnn39ekvTkk09q8ODBGj3auyTA+vXr9dvf/lZ33XWXad+hv7r13KF6d0eZPims1IK/bNbKH2XLGtJ5dyIAAH3B1HAzd+5cVVRUaPHixSopKdH48eO1atUqZWRkSJJKSkrazXnj8Xi0cOFCFRYWKjQ0VMOGDdNDDz2kH/3oR2Z9hX7LGmLRI9dM1OzH12nT/qN6au1e/fusYWaXBQCAufPcmIF5bnrWXzYV6yevbJEtNERv/+cMDU2MMrskAEAQCoh5bhAcrslK04wRCXK3eLTode6eAgCYj3CD02KxWPTLORPkCAvRh3sr9Er+AbNLAgD0c4QbnLbB8RG65yLv3VO/XLVDFXXcvQYAMA/hBj3iB+dmakxqjKoamvU/f9tG9xQAwDSEG/SIMGuIHrpqgqwhFr25tURPrt5tdkkAgH6KcIMeMzE9VouvHCdJ+u0/d+q9Lw6bXBEAoD8i3KBHfW9ahm7O9s5T9JNXtqic8TcAgD5GuEGPW3jpGI1KjlZ5nVv/9dfP5PEw/gYA0HcIN+hxjjCrHps7SbbQEK3+8ogee3en2SUBAPoRwg16xdiBMcr9zgRJ0v97b7dWbS0xuSIAQH9BuEGv+W5Wmm49N1OSdO9fPtOOkhqTKwIA9AeEG/SqhbNH69zhCWpsbtWtKzaqpLrR7JIAAEGOcINeFWoN0dIbJmtoQqQOVTfpxmc+0dF6t9llAQCCGOEGvS42wqbnbz1LKTEO7S6r0y0rNqre1WJ2WQCAIEW4QZ9IGxChP916lmIjwvRZcZXm/TlfrpZWs8sCAAQhwg36zIjkaP3xljMVYbNq3a5yLfjLZ2plDhwAQA8j3KBPTR48QL/7tyyFWS16c0uJ/udvn7PIJgCgRxFu0OdmjkzUo9dOksUivfBxkX7zzpcEHABAjyHcwBRXTByoxVeOlyQte3+PHvj7NpZpAAD0CMINTHPj2Rl68NvjZLFIz324X/fRRQUA6AGEG5jq5ulD9Ng3uqgAADgdhBuYbs7kQfrlHO86VMve36Pfr9ljckUAgEBGuIFfuGHaYP30ktGSpNy3vtBLnxSZXBEAIFARbuA3/n3WMM07b5gk6b9f36p/bDlkckUAgEBEuIFf+eklo3TDtMEyDOmelZv1/pdlZpcEAAgwhBv4FYvFov+9crwuPyNVza2G5v05Xxv3VZpdFgAggBBu4HesIRY9eu0kzRqVqKZmj36wYqO2Hao2uywAQIAg3MAv2UJDtPx7WTprSJxqm1r0vac/pgUHANAlhBv4rXCbVU/fMlWT0mNV1dCs7z39sd7ZVmp2WQAAP0e4gV+LcYTppR+erZyxyXK3ePQfL3yq//uMu6gAACdGuIHfC7dZtex7U3TV5EFq9Rj6z5cL9Gr+AbPLAgD4KcINAkKoNUS/vWairjszXR5D+vErn+nFj5noDwDQEeEGASMkxKJffWeCbs7OkGF4J/p7et1eFtsEALRDuEFACQmx6IFvj9PtM4dKkn7x5g7d/qd8VTW4Ta4MAOAvCDcIOBaLRQtnj9Z9l4+VzRqivO2H9Z1lG1RYXm92aQAAP0C4QUCyWCy69dxMvX7HdA2KDVdheb2+s+wDfbS3wuzSAAAmI9wgoI0b6NQbd5zjmwvnxmc+1h/W7lWrh3E4ANBfEW4Q8BKj7Xr59rN12bH1qH65aoeuf+ojldU2mV0aAMAEhBsEBUeYVUuvn6zcqyYoyh6qT/ZV6or/t14FRUfNLg0A0McINwgaFotF1581WP9317kakRSlwzUuzf39R3rpkyJuFweAfoRwg6CTmRCp1+84R98alyx3q0cLX9uqeX/OV0Wdy+zSAAB9gHCDoBRlD9Xy72XpZ7NHK8xq0TvbDutbS9bqXzsOm10aAKCXEW4QtEJCLJp33jC9ccc5GpUcrfI6t259bpMWvrZF9a4Ws8sDAPQSwg2C3riBTv3tznP0wxmZsliklz4p1uzH12nTvkqzSwMA9ALTw82yZcuUmZkph8OhrKwsrVu37oTHvvbaa7r44ouVmJiomJgYZWdn65133unDahGoHGFWLbpsrF687WwNig1XUWWDrv39h3r47S/kbvGYXR4AoAeZGm5Wrlyp+fPna9GiRSooKNCMGTM0e/ZsFRUdf7XntWvX6uKLL9aqVauUn5+v888/X1dccYUKCgr6uHIEquxh8Xpr/gxdNWWQPIa07P09mvPkB/qytNbs0gAAPcRimHiP7LRp0zRlyhQtX77ct2/MmDGaM2eOcnNzu/Qe48aN09y5c/U///M/XTq+pqZGTqdT1dXViomJ6VbdCA5vbS3Rf7++VUcbmhVikS4Zn6IFF4/S8KQos0sDAHzDqfz9Nq3lxu12Kz8/Xzk5Oe325+TkaMOGDV16D4/Ho9raWsXFxZ3wGJfLpZqamnYbIEmzJ6TqnfkzlTM2WR5DWrW1VJc+vk6Pv7uLrioACGCmhZvy8nK1trYqOTm53f7k5GSVlpZ26T0eeeQR1dfX69prrz3hMbm5uXI6nb4tPT39tOpGcEmKceipm6bq7fkzNGtUotytHj327k5d9sQ65e9nwDEABCLTBxRbLJZ2jw3D6LDveF566SU98MADWrlypZKSkk543MKFC1VdXe3biouLT7tmBJ/RKTH64y1n6vHrJik+0qZdZXW6+ncf6n/+9rnquG0cAAKKaeEmISFBVqu1QytNWVlZh9acb1q5cqVuvfVW/eUvf9FFF13U6bF2u10xMTHtNuB4LBaLrpw0SO8uOE9XZ6XJMKTnP9yvbz22VnnbD7OEAwAECNPCjc1mU1ZWlvLy8trtz8vL0/Tp00/4updeekm33HKLXnzxRV122WW9XSb6oQGRNv32mol64bZpShsQroNVjfrh85t0/R8+0uovyuTxEHIAwJ+Z2i21YMECPf3003r22We1Y8cO3XPPPSoqKtK8efMkebuUbrrpJt/xL730km666SY98sgjOvvss1VaWqrS0lJVV1eb9RUQxM4ZnqB35s/UvPOGyWYN0Ud7K/X9FRv1nWUfaCMTAAKA3zL1VnDJO4nfww8/rJKSEo0fP16PPfaYZs6cKUm65ZZbtG/fPr3//vuSpFmzZmnNmjUd3uPmm2/WihUruvR53AqO7jhwtEErPtinlz4pUr27VZJ02YRU/fSS0RocH2FydQAQ/E7l77fp4aavEW5wOspqm/RY3k6t3FgsjyHZrCH63tmDdd2ZgzUqJdrs8gAgaBFuOkG4QU/YUVKjX765Q+t3l/v2jU6J1tVZafretAyF26wmVgcAwYdw0wnCDXqKYRhau6tcL368X+99UabmVu//Sskxdv3nhSN1zdQ0hVlNn20BAIIC4aYThBv0hqoGt/5vS4l+9/4eHaxqlCRlxEfohzOG6uqsNDnCaMkBgNNBuOkE4Qa9ydXSqhc/LtLS93arot4tSYqLtOmm7AzdeHaG4qPsJlcIAIGJcNMJwg36Qr2rRX/ZVKxn1hfqwFFvS449NERXZ6Xp1nMzNTSRxTkB4FQQbjpBuEFfamn16O1tpXpq7V5tOfDVfEyzRiXq5uwhOm9kokJCTr7cCAD0d4SbThBuYAbDMPRxYaX+sHav3vuyTG3/1w2Oi9BN2Rm6Jitdzogwc4sEAD9GuOkE4QZm21derz9/tF9/2VSsmibvopyOsBDNmTRIN2UP0diBXJcA8E2Em04QbuAvGtwt+tvmQ3puwz59UVrr23/20Dj9aOYwzRyZKCtdVgAgiXDTKcIN/I1hGNq476ie/3Cf3v68VC3HFuYcFBuu72al6ZqsNKXHscQDgP6NcNMJwg382aGqRj27vlB/zT+g6sZm3/5zhsfr+rMG61vjUpgYEEC/RLjpBOEGgaCpuVX/3H5Yf9lY3G6Jh6Rou64/a7BumDZYyTEOEysEgL5FuOkE4QaBpriyQX/dVKyXNhbrSK1LkhQaYlHOuGTNHp+q80cnKcoeanKVANC7CDedINwgULlbvHPm/OnDfdq476hvf3iYVbMnpOjqrDSdnRnPvDkAghLhphOEGwSD7Ydq9LfPDuqdz0u1r6LBtz8u0qbsYfGaPT5FF4xOUoSNFh0AwYFw0wnCDYKJYRj6tKhKr+Qf0D+2HFLtsXlzJG+LzoVjknTFxIE6b2Qii3cCCGiEm04QbhCsmls9+qy4Su/uKNM/thzyrWklSdH2UF08NllXTByoc4YnyBbKHVcAAgvhphOEG/QHhmHoswPV+sdnh/Tm1hKVVDf5nou2h+q8UYm6eGyyZo1KkjOcZR8A+D/CTScIN+hvPB5DnxYd1T+2lOjNrSW+O64k711XZw6J05mZcZo+LF5nDoljVmQAfolw0wnCDfozj8fQ5gNVenf7YeVtP6xdZXXtnk+Isuu8kYmaOTJBM0YkKi7SZlKlANAe4aYThBvgK/vK67Vud7ny91Vq9ZdH2s2KbLFIWYMH6OKxybpobLKGJUaZWCmA/o5w0wnCDXB87haPNu6r1NqdR7Rm55F2i3lK0tCESJ03KlHTMuM1LTNOA2jVAdCHCDedINwAXXOoqlHv7vB2X320t0LNre3/qRiVHK1pQ+N07vAETR+ewCzJAHoV4aYThBvg1NU2NWvtznJt2FOuTworO4zVCQ2xaErGAJ03MlHnDk/Q+EFOBiYD6FGEm04QboDTV17n0sbCSn24t0Jrdx5pN0uy5L3d/KzMOGUPi9fZQ+M1NjWGZSEAnBbCTScIN0DP219Rf2ysTrk+3luhWldLu+fjI22aMSJBM0cmasaIRCVG202qFECgItx0gnAD9K5Wj6Fth6r14Z4KfbS3Qp8UVqre3drumNEp0Zo8OFbDEqM0MjlaU4cMYB0sAJ0i3HSCcAP0LXeLR58WHdWanUe0ducRbTtU0+GYMKtFk9JjNS0zXhPTYzUxzamkGIcJ1QLwV4SbThBuAHMdqXUpf/9RfX6wWoXl9dpcXKWDVY0djkt1OjQxLVZnpDs1KS1W49OcinGwVATQXxFuOkG4AfyLYRgqqmzQh3sq9GnRUX1WXK1dZbXyfONfJotFGp4YpcmDYzV58ABNHhyrEUnR3JUF9BOEm04QbgD/V+9q0ecHq7XlQLU2H6jSlgNVKq7s2LoTZQ/VxHSnJqd7w86k9FjFRzFYGQhGhJtOEG6AwFRR59Lm4ip9WnRUBUVV+qy4qsNAZUkaEh/ha9mZnD5Ao1OjFWYNMaFiAD2JcNMJwg0QHFo9hnaV1erT/VUqKDqqguIq7f7G5IKSZA8N0RlpTk0ZPEBnpMVqVEq0Up0ORdissljo0gICBeGmE4QbIHhVNzZrc/GxsFPk/VnT1HLcY6PsoRqTGq1xA50aOzBGY1NjNDI5WrZQWnkAf0S46QThBug/PB5De8vrVVB0VJ8WVWn7oWrtLqs7bneW5L0lfURStMYNjNG4gTEaO9CpManRiuYuLcB0hJtOEG4ANLhbVFzZqG2HqrXtUI22HarW9kM1J2zlGRwXodEp0RqdGqORyVEakRStzIRIWnmAPkS46QThBsDxGIahA0cbte1QjbYfCz3bS2pUUt103OOtIRYNiY/Q8CRv2BmRHKXhSVEalhglR5i1j6sHgh/hphOEGwCnoqLOpS9La/VFaa2+KK3RrrI67T5c12H9rDYWi5Q2IFzDEqM0NCFKw5IiNTwxSsOSohQfaWMQM9BNhJtOEG4AnC7DMHS4xqVdZbXadbhOu8rqtKesTjvLalXV0HzC18VGhGlYYtSxsBPp/T0pSmkDIpiMEDgJwk0nCDcAeothGKqod2tPWZ32HKnXniN1vu3A0Uad6F9bW2iIhiZ4w86wxEgNO9a9NSwxSuE2urgA6dT+frMMLwD0EIvFooQouxKi7Jo2NL7dc43uVhWW12v3EW8rT9vPveX1crd4jnV71XZ4z0Gx4cpMiFRGfISGxHt/ZiZEKj0ugrE9wAnQcgMAJmr1GDp4tFF7jtRpd1md7+fuI3WddnFZLFJqjENDEiKVER+pIfERGpIQqSHxkRocF0GLD4IO3VKdINwACBSV9W7tOVKnfeX12l/RoMKKeu2vqNe+8gbVnWBAc5vkGLvSBkQobUD4sS3C93NgrEP2UMIPAgvhphOEGwCBzjAMVda7te9Y0NlfUa/CimM/y+tVe4L5etpYLFJytENpA8I1aEC4UpwOpcR4t/S4CKXHRcgZzsSF8C8BFW6WLVum3/zmNyopKdG4ceO0ZMkSzZgx47jHlpSU6N5771V+fr527dqlu+++W0uWLDmlzyPcAAhmhmHoaEOziisbdOBoow4c/ebPRjU2H3+G5q9zhodpcFyEBsdHeH/GeVt+vOtyhSrSHqoYRyi3tqPPBMyA4pUrV2r+/PlatmyZzjnnHP3+97/X7NmztX37dg0ePLjD8S6XS4mJiVq0aJEee+wxEyoGAP9msVgUF2lTXKRNE9NjOzzf1upz4GijDlZ5Q09ptUuHa5pUUt2oospGlde5VN3YrK0Hq7X1YPUJPyvKHqpUp0MDY8O929d+T3U6lOJ0MOgZpjC15WbatGmaMmWKli9f7ts3ZswYzZkzR7m5uZ2+dtasWZo0aRItNwDQw9qWpyiqbPBuFfXaX9mgQ1WNKq1uUlOLR+4WT5feKy7SppQYhy/sDIwNb/c41RnO4Gd0SUC03LjdbuXn5+tnP/tZu/05OTnasGFDj32Oy+WSy+XyPa6pqemx9waAYBRhC9WolGiNSok+4TGN7lYdqm5USVWTDlV5W4EOVTWqpNr7+FB1o5qaPaqsd6uy3q3tJSf+tzc2Isw75ufY2J/kY+En2XksBMU45AwPowsMXWZauCkvL1dra6uSk5Pb7U9OTlZpaWmPfU5ubq4efPDBHns/AIAUbrP6Jho8HsMwVN3YrJLqJpVWN6mk2tvt9dVj7+8N7lZVNTSrqqH5uPP8tHGEhSj5WPBJjnEoOdru/en86vekGLsibEzfBj+YxO+bSdwwjB5N5wsXLtSCBQt8j2tqapSent5j7w8A6MhisSg2wqbYCJvGpB6/C8EwDNU0taik2tvd5R334/3ZFogO1zTpaEOzmpo92l/RoP0VDZ1+brQ9VEkxdiVFO5QcY1dSjENJ0d6JFdvGIsVH2ZQQZVeYlVXdg5Vp4SYhIUFWq7VDK01ZWVmH1pzTYbfbZbfbe+z9AAA9w2KxyBkeJmd4mEannHgMRVNzqw7XNOlwjevYz6bjPHapsblVta4W1R5p0Z4j9Sf5bCkuwqbEaLsSo71hKCHapsRjM0wnRNmVEO0NQQMibKz9FWBMCzc2m01ZWVnKy8vTd77zHd/+vLw8XXnllWaVBQDwM44wqzLivTMxn4hhGKpztehwjUtlNU0qq/UGn7afbWN/Kuvdqqh3q9XjXQesot7daXeYJIVYpAERX7X6xEfZFX+sFSgu0ts6FRdh04DIMCVG2RUfZScMmczUbqkFCxboxhtv1NSpU5Wdna2nnnpKRUVFmjdvniRvl9LBgwf1/PPP+16zefNmSVJdXZ2OHDmizZs3y2azaezYsWZ8BQCAH7BYLIp2hCnaEabhSccfB9TG4zFU2eDWkVqXympdx3426UitSxV1bpXXuY5tbh1tcMtjyBeEdpWdvJYQixQX2dYi1P5nWytRfJQ3EDnDwxRCEOpxpoabuXPnqqKiQosXL1ZJSYnGjx+vVatWKSMjQ5J30r6ioqJ2r5k8ebLv9/z8fL344ovKyMjQvn37+rJ0AECACgn5aoHTMamdH9vS6lFlw7EWn2PBp7K+7Wezqhq8AehofbMq6t2qrHfJY8gXkHaUnKQWi3fCxAGRNiVE2n3jgdpaiBKP/YxxhMkaIsU4vMcyXqhzps9Q3NeY5wYA0Fu83V2udq1CX9/Kar1dZZV1btWeZH2wzsQ4QhX/9UHSX+sm++bg6QERtqCYTDEg5rkBACDYWEMsSop2KCnaoXEnOdbd4lFVo1tVDc2qqHP7WoQq6lw6UudWRZ1LFcf21TW1qMVjqLapWR5DqmlqUU1TiwrLOx843cYRFuIbvB0bblNMeJhiI9oeh8l57HdneJhij3WXxYaHKSY8LCDHDxFuAAAwgS00xBeE1MWbhFs93vmDKutdvkBU8Y3B0l9/rrLerRaPoaZmj5qaXTpc4zr5h3xDtCP0a8GnLQTZfPtiwr3Pxzi8Ycj7u7dlySyEGwAAAoQ15Ku1w4Ynnfx4wzBU62pRdUOzqhu/2qqOPa5qdKvm64+/dlzdsW6z2qYW1Ta16MDRxi7X6QwP02f353T3a542wg0AAEHKYrF4W1QcYTrV6WubWz2qaQtDbcHoayHIG4xaVNPUrJrGZm9XWaP399iIsF75Pl1FuAEAAB2EWUO8c/p0o3vJ4zH3XiXuJQMAAD3K7Ll7CDcAACCoEG4AAEBQIdwAAICgQrgBAABBhXADAACCCuEGAAAEFcINAAAIKoQbAAAQVAg3AAAgqBBuAABAUCHcAACAoEK4AQAAQYVwAwAAgkqo2QX0NcPwLsNeU1NjciUAAKCr2v5ut/0d70y/Cze1tbWSpPT0dJMrAQAAp6q2tlZOp7PTYyxGVyJQEPF4PDp06JCio6NlsVh69L1ramqUnp6u4uJixcTE9Oh7BxvO1anhfHUd5+rUcL66jnPVdb1xrgzDUG1trQYOHKiQkM5H1fS7lpuQkBClpaX16mfExMRw4XcR5+rUcL66jnN1ajhfXce56rqePlcna7Fpw4BiAAAQVAg3AAAgqBBuepDdbtf9998vu91udil+j3N1ajhfXce5OjWcr67jXHWd2eeq3w0oBgAAwY2WGwAAEFQINwAAIKgQbgAAQFAh3AAAgKBCuOkhy5YtU2ZmphwOh7KysrRu3TqzS/ILDzzwgCwWS7stJSXF97xhGHrggQc0cOBAhYeHa9asWdq2bZuJFfedtWvX6oorrtDAgQNlsVj0xhtvtHu+K+fG5XLprrvuUkJCgiIjI/Xtb39bBw4c6MNv0TdOdq5uueWWDtfZ2Wef3e6Y/nKucnNzdeaZZyo6OlpJSUmaM2eOvvzyy3bHcG19pSvni+vLa/ny5TrjjDN8E/NlZ2frrbfe8j3vT9cV4aYHrFy5UvPnz9eiRYtUUFCgGTNmaPbs2SoqKjK7NL8wbtw4lZSU+LatW7f6nnv44Yf16KOPaunSpdq4caNSUlJ08cUX+9YAC2b19fWaOHGili5detznu3Ju5s+fr9dff10vv/yy1q9fr7q6Ol1++eVqbW3tq6/RJ052riTpkksuaXedrVq1qt3z/eVcrVmzRnfccYc++ugj5eXlqaWlRTk5Oaqvr/cdw7X1la6cL4nrS5LS0tL00EMPadOmTdq0aZMuuOACXXnllb4A41fXlYHTdtZZZxnz5s1rt2/06NHGz372M5Mq8h/333+/MXHixOM+5/F4jJSUFOOhhx7y7WtqajKcTqfxu9/9ro8q9A+SjNdff933uCvnpqqqyggLCzNefvll3zEHDx40QkJCjLfffrvPau9r3zxXhmEYN998s3HllVee8DX99VwZhmGUlZUZkow1a9YYhsG1dTLfPF+GwfXVmQEDBhhPP/20311XtNycJrfbrfz8fOXk5LTbn5OTow0bNphUlX/ZtWuXBg4cqMzMTF133XXau3evJKmwsFClpaXtzp3dbtd5553X789dV85Nfn6+mpub2x0zcOBAjR8/vl+ev/fff19JSUkaOXKkfvjDH6qsrMz3XH8+V9XV1ZKkuLg4SVxbJ/PN89WG66u91tZWvfzyy6qvr1d2drbfXVeEm9NUXl6u1tZWJScnt9ufnJys0tJSk6ryH9OmTdPzzz+vd955R3/4wx9UWlqq6dOnq6Kiwnd+OHcddeXclJaWymazacCAASc8pr+YPXu2XnjhBb333nt65JFHtHHjRl1wwQVyuVyS+u+5MgxDCxYs0Lnnnqvx48dL4trqzPHOl8T19XVbt25VVFSU7Ha75s2bp9dff11jx471u+uq360K3lssFku7x4ZhdNjXH82ePdv3+4QJE5Sdna1hw4bpueee8w3I49ydWHfOTX88f3PnzvX9Pn78eE2dOlUZGRl68803ddVVV53wdcF+ru68805t2bJF69ev7/Ac11ZHJzpfXF9fGTVqlDZv3qyqqiq9+uqruvnmm7VmzRrf8/5yXdFyc5oSEhJktVo7pM6ysrIOCRZSZGSkJkyYoF27dvnumuLcddSVc5OSkiK3262jR4+e8Jj+KjU1VRkZGdq1a5ek/nmu7rrrLv3973/X6tWrlZaW5tvPtXV8Jzpfx9Ofry+bzabhw4dr6tSpys3N1cSJE/X444/73XVFuDlNNptNWVlZysvLa7c/Ly9P06dPN6kq/+VyubRjxw6lpqYqMzNTKSkp7c6d2+3WmjVr+v2568q5ycrKUlhYWLtjSkpK9Pnnn/f781dRUaHi4mKlpqZK6l/nyjAM3XnnnXrttdf03nvvKTMzs93zXFvtnex8HU9/vr6+yTAMuVwu/7uuenR4cj/18ssvG2FhYcYzzzxjbN++3Zg/f74RGRlp7Nu3z+zSTHfvvfca77//vrF3717jo48+Mi6//HIjOjrad24eeughw+l0Gq+99pqxdetW4/rrrzdSU1ONmpoakyvvfbW1tUZBQYFRUFBgSDIeffRRo6CgwNi/f79hGF07N/PmzTPS0tKMd9991/j000+NCy64wJg4caLR0tJi1tfqFZ2dq9raWuPee+81NmzYYBQWFhqrV682srOzjUGDBvXLc/Xv//7vhtPpNN5//32jpKTEtzU0NPiO4dr6ysnOF9fXVxYuXGisXbvWKCwsNLZs2WL893//txESEmL885//NAzDv64rwk0PefLJJ42MjAzDZrMZU6ZMaXcbYX82d+5cIzU11QgLCzMGDhxoXHXVVca2bdt8z3s8HuP+++83UlJSDLvdbsycOdPYunWriRX3ndWrVxuSOmw333yzYRhdOzeNjY3GnXfeacTFxRnh4eHG5ZdfbhQVFZnwbXpXZ+eqoaHByMnJMRITE42wsDBj8ODBxs0339zhPPSXc3W88yTJ+OMf/+g7hmvrKyc7X1xfX/nBD37g+zuXmJhoXHjhhb5gYxj+dV1ZDMMwerYtCAAAwDyMuQEAAEGFcAMAAIIK4QYAAAQVwg0AAAgqhBsAABBUCDcAACCoEG4AAEBQIdwAAICgQrgB0KtmzZql+fPnm11GOxaLRW+88YbZZQDoJcxQDKBXVVZWKiwsTNHR0RoyZIjmz5/fZ2HngQce0BtvvKHNmze3219aWqoBAwbIbrf3SR0A+lao2QUACG5xcXE9/p5ut1s2m63br09JSenBagD4G7qlAPSqtm6pWbNmaf/+/brnnntksVhksVh8x2zYsEEzZ85UeHi40tPTdffdd6u+vt73/JAhQ/SLX/xCt9xyi5xOp374wx9Kkn76059q5MiRioiI0NChQ3XfffepublZkrRixQo9+OCD+uyzz3yft2LFCkkdu6W2bt2qCy64QOHh4YqPj9ftt9+uuro63/O33HKL5syZo9/+9rdKTU1VfHy87rjjDt9nAfAvhBsAfeK1115TWlqaFi9erJKSEpWUlEjyBotvfetbuuqqq7RlyxatXLlS69ev15133tnu9b/5zW80fvx45efn67777pMkRUdHa8WKFdq+fbsef/xx/eEPf9Bjjz0mSZo7d67uvfdejRs3zvd5c+fO7VBXQ0ODLrnkEg0YMEAbN27UX//6V7377rsdPn/16tXas2ePVq9ereeee04rVqzwhSUA/oVuKQB9Ii4uTlarVdHR0e26hX7zm9/ohhtu8I3DGTFihJ544gmdd955Wr58uRwOhyTpggsu0I9//ON27/nzn//c9/uQIUN07733auXKlfrJT36i8PBwRUVFKTQ0tNNuqBdeeEGNjY16/vnnFRkZKUlaunSprrjiCv36179WcnKyJGnAgAFaunSprFarRo8ercsuu0z/+te/fK1IAPwH4QaAqfLz87V792698MILvn2GYcjj8aiwsFBjxoyRJE2dOrXDa1955RUtWbJEu3fvVl1dnVpaWhQTE3NKn79jxw5NnDjRF2wk6ZxzzpHH49GXX37pCzfjxo2T1Wr1HZOamqqtW7ee0mcB6BuEGwCm8ng8+tGPfqS77767w3ODBw/2/f718CFJH330ka677jo9+OCD+ta3viWn06mXX35ZjzzyyCl9vmEY7cb/fN3X94eFhXV4zuPxnNJnAegbhBsAfcZms6m1tbXdvilTpmjbtm0aPnz4Kb3XBx98oIyMDC1atMi3b//+/Sf9vG8aO3asnnvuOdXX1/sC1AcffKCQkBCNHDnylGoC4B8YUAygzwwZMkRr167VwYMHVV5eLsl7x9OHH36oO+64Q5s3b9auXbv097//XXfddVen7zV8+HAVFRXp5Zdf1p49e/TEE0/o9ddf7/B5hYWF2rx5s8rLy+VyuTq8z/e+9z05HA7dfPPN+vzzz7V69WrddddduvHGG31dUgACC+EGQJ9ZvHix9u3bp2HDhikxMVGSdMYZZ2jNmjXatWuXZsyYocmTJ+u+++5Tampqp+915ZVX6p577tGdd96pSZMmacOGDb67qNp897vf1SWXXKLzzz9fiYmJeumllzq8T0REhN555x1VVlbqzDPP1NVXX60LL7xQS5cu7bkvDqBPMUMxAAAIKrTcAACAoEK4AQAAQYVwAwAAggrhBgAABBXCDQAACCqEGwAAEFQINwAAIKgQbgAAQFAh3AAAgKBCuAEAAEGFcAMAAILK/wcLULJ+bqopZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1f6bc-f2ba-4b06-9109-7778966e1379",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78f947-6f88-4871-8005-d5732cd8e2d9",
   "metadata": {},
   "source": [
    "<b>Identify the first four misclassified samples using the validation data:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d0864db-4423-447e-b379-407e707efb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample : 1; Expected Label: tensor([0]); Obtained Label: tensor([1])\n",
      "Sample : 26; Expected Label: tensor([1]); Obtained Label: tensor([0])\n",
      "Sample : 79; Expected Label: tensor([0]); Obtained Label: tensor([1])\n",
      "Sample : 245; Expected Label: tensor([0]); Obtained Label: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "max_num_of_items = 4  # first four mis-classified samples\n",
    "validation_loader_batch_one = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1)\n",
    "\n",
    "for i, (x_test, y_test) in enumerate(validation_loader_batch_one):\n",
    "    # set model to eval\n",
    "    model.eval()\n",
    "    \n",
    "    # make a prediction\n",
    "    z = model(x_test)\n",
    "    \n",
    "    # find max\n",
    "    _, yhat = torch.max(z.data, 1)\n",
    "    \n",
    "    # print mis-classified samples\n",
    "    if yhat != y_test:\n",
    "        print(\"Sample : {}; Expected Label: {}; Obtained Label: {}\".format(str(i), str(y_test), str(yhat)))\n",
    "        count += 1\n",
    "        if count >= max_num_of_items:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b8fe6-26bd-4bb9-b8da-1ca492528ee6",
   "metadata": {},
   "source": [
    "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\"> CLICK HERE </a> Click here to see how to share your notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f20a3f-7d1b-4aea-9e74-e373ec30e1bb",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb64cce-3fe5-489d-bced-79c3e7a447cf",
   "metadata": {},
   "source": [
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-21  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a379170-e56f-40f9-9f8f-e3227416419a",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">MIT License</a>.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
